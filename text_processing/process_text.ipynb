{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting EU Texts into Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### structural components of legal texts\n",
    "\n",
    "articles_enumerated =  ['Article {}'.format(i) for i in range(1,350)]\n",
    "\n",
    "sections = ['\\nSection 1\\n', '\\nSection 2\\n', '\\nSection 3\\n', '\\nSection 4\\n', \n",
    "            '\\nSection 5\\n', '\\nSection 6\\n', '\\nSection 7\\n', \n",
    "            '\\nSECTION 1\\n', '\\nSECTION 2\\n', '\\nSECTION 3\\n', '\\nSECTION 4\\n', \n",
    "            '\\nSECTION 5\\n', '\\nSECTION 6\\n', '\\nSection 7\\n', \n",
    "            'Section 1', 'Section 2', 'Section 3', 'Section 4', \n",
    "            'Section 5', 'Section 6', 'Section 7', \n",
    "            'SECTION 1', 'SECTION 2', 'SECTION 3', 'SECTION 4', \n",
    "            'SECTION 5', 'SECTION 6', 'SECTION 7'] \n",
    "\n",
    "chapters=  ['CHAPTER I', 'CHAPTER II', 'CHAPTER III', 'CHAPTER IV', 'CHAPTER V', 'CHAPTER VI', 'CHAPTER VII',\n",
    "            'CHAPTER 1', 'CHAPTER 2', 'CHAPTER 3', 'CHAPTER 4', 'CHAPTER 5', 'CHAPTER 6', 'CHAPTER 7',\n",
    "            '\\nCHAPTER I\\n', '\\nCHAPTER II\\n', '\\nCHAPTER III\\n', '\\nCHAPTER IV\\n', '\\nCHAPTER V\\n', \n",
    "            '\\nCHAPTER VI\\n', '\\nCHAPTER VII\\n',\n",
    "            '\\nCHAPTER 1\\n', '\\nCHAPTER 2\\n', '\\nCHAPTER 3\\n', '\\nCHAPTER 4\\n', '\\nCHAPTER 5\\n', \n",
    "            '\\nCHAPTER 6\\n', '\\nCHAPTER 7\\n',]\n",
    "        \n",
    "titles = ['TITLE I', 'TITLE II', 'TITLE III', 'TITLE IV', 'TITLE V', 'TITLE VI', 'TITLE VII', 'TITLE VIII'\n",
    "         'TITLE 1', 'TITLE 2', 'TITLE 3', 'TITLE 4', 'TITLE 5', 'TITLE 6', 'TITLE 7', 'TITLE 8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split the laws\n",
    "The function 'process_text' takes in an html file of an EU law as can be dowloaded from EUR-Lex https://eur-lex.europa.eu/homepage.html and splits it into articles. It assumes that the files are stored in the directory 'texts'. Refer to download_searches.py for downloading EU laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all EU text\n",
    "timeperiod = '2000-2019'\n",
    "#timeperiod = '2000-2019'\n",
    "\n",
    "\n",
    "texts = os.listdir(f'texts/{timeperiod}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \n",
    "    ##read legal text\n",
    "    f = codecs.open(\"../texts/{}\".format(text), 'r', 'utf-8')\n",
    "    ## parse with beatiful soup\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    ##close file\n",
    "    f.close()\n",
    "    \n",
    "    ##only use body text\n",
    "    body = soup.find('body')\n",
    "    text_only = body\n",
    "    ##xreate list with paragraphs\n",
    "    paragraphs = text_only.find_all('p')\n",
    "\n",
    "    i=0 ##article counter\n",
    "    j=0 ##title counter\n",
    "    k=0 ##chapter counter\n",
    "    l=0 ##section counter\n",
    "    \n",
    "    ##check if folder for text already exists\n",
    "    if not os.path.exists(text[:-5]):\n",
    "        os.mkdir(text[:-5])\n",
    "\n",
    "    ##open new file for the fron text    \n",
    "    file = open( text[:-5] + '/' +  text[:-5] +'_' + 'front.txt', \"w\", encoding  = 'utf-8')\n",
    "    \n",
    "    ##create iterable for paragraphs (sueful for skipping certain paragraphs)\n",
    "    paragraphs_iter = iter(paragraphs[3:])\n",
    "\n",
    "\n",
    "    ## ITERATE OVER PARAGPHS\n",
    "    for paragraph in paragraphs_iter:\n",
    "        \n",
    "        string = paragraph.text.replace(u'\\xa0', u' ')\n",
    "    \n",
    "        ##catch whereas\n",
    "        if string == 'Whereas:':\n",
    "            file.close()\n",
    "            file = open( text[:-5] + '/' +  text[:-5] +'_' + 'Whereas' + '.txt', \"w\", encoding  = 'utf-8')\n",
    "\n",
    "        if string in titles:\n",
    "            j+=1\n",
    "            ##resets chapter index\n",
    "            k=0\n",
    "            next(paragraphs_iter)\n",
    "            continue\n",
    "\n",
    "\n",
    "        if string in chapters:\n",
    "            k+=1\n",
    "            next(paragraphs_iter)\n",
    "            continue\n",
    "\n",
    "\n",
    "        if string in sections:\n",
    "            l+=1\n",
    "            next(paragraphs_iter)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        ## catch ending\n",
    "        if string == 'For the European Parliament':\n",
    "            file.close()\n",
    "            break\n",
    "        if string[:18] == 'Done at Luxembourg':\n",
    "            file.close()\n",
    "            break\n",
    "        if string[:16] == 'Done at Brussels':\n",
    "            file.close()\n",
    "            break \n",
    "        if string[:18] == 'Done at Strasbourg':\n",
    "            file.close()\n",
    "            break    \n",
    "\n",
    "\n",
    "        if string in articles_enumerated:        \n",
    "            file.close()\n",
    "            i += 1\n",
    "            file = open( text[:-5] + '/' +  text[:-5] + '_' \n",
    "                            + 'Title_' + str(j) +'_'\n",
    "                            + 'Chapter_' + str(k) +'_'\n",
    "                            + 'Section_' +str(l) +'_'\n",
    "                            + 'Article_' +'000'[:3-len(str(i))] + str(i) + '.txt', \"w\", encoding  = 'utf-8')\n",
    "            file.write(paragraph.text + '\\n')\n",
    "\n",
    "        else:    \n",
    "            file.write(paragraph.text + '\\n')\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the text\n",
    "This part executes the function to split the laws into articles and and saves them in a folder 'processed'. All articles for each law are stored in a separate folder that is labeled with the respective CELEX number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'processed/2000-2019'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtimeperiod\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'processed/2000-2019'"
     ]
    }
   ],
   "source": [
    "os.chdir(f'processed/{timeperiod}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../texts/EU_32000L0008.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_text\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m##read legal text\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../texts/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m## parse with beatiful soup\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m<frozen codecs>:918\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../texts/EU_32000L0008.html'"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
