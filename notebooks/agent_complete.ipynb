{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdda930",
   "metadata": {},
   "source": [
    "# LLM-Based Automatic Policy Text Classifier\n",
    "This notebook demonstrates a multi-step approach to automatically annotate policy articles using an LLM (Anthropic Claude), informed by the coding scheme in the Appendix and Codebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## 0. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install python-dotenv requests numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our custom modules\n",
    "from src.agent.utils import (\n",
    "    get_project_root, \n",
    "    load_coding_scheme, \n",
    "    filter_coding_scheme,\n",
    "    load_raw_text,\n",
    "    load_curated_annotations,\n",
    "    create_extended_coding_scheme\n",
    ")\n",
    "\n",
    "from src.agent.annotation import (\n",
    "    annotate_article,\n",
    "    load_few_shot_examples,\n",
    "    prepare_annotation_prompt\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "assert ANTHROPIC_API_KEY, 'Please set your ANTHROPIC_API_KEY in the .env file.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coding-scheme-section",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Coding Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-coding-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full coding scheme has 3 layers\n",
      "\n",
      "Layer: Policydesigncharacteristics\n",
      "  - Tagset: Objective (4 tags)\n",
      "  - Tagset: Reference (3 tags)\n",
      "  - Tagset: Actor (8 tags)\n",
      "  - Tagset: Resource (3 tags)\n",
      "  - Tagset: Time (5 tags)\n",
      "  - Tagset: Compliance (2 tags)\n",
      "  - Tagset: Reversibility (1 tags)\n",
      "\n",
      "Layer: Technologyandapplicationspecificity\n",
      "  - Tagset: EnergySpecificity (2 tags)\n",
      "  - Tagset: ApplicationSpecificity (2 tags)\n",
      "  - Tagset: TechnologySpecificity (2 tags)\n",
      "\n",
      "Layer: Instrumenttypes\n",
      "  - Tagset: InstrumentType (10 tags)\n"
     ]
    }
   ],
   "source": [
    "# Load the full coding scheme\n",
    "coding_scheme = load_coding_scheme()\n",
    "print(f\"Full coding scheme has {len(coding_scheme.get('layers', []))} layers\")\n",
    "\n",
    "# Display all layer and tagset names\n",
    "for layer in coding_scheme.get('layers', []):\n",
    "    print(f\"\\nLayer: {layer.get('layer')}\")\n",
    "    for tagset in layer.get('tagsets', []):\n",
    "        tag_count = len(tagset.get('tags', []))\n",
    "        print(f\"  - Tagset: {tagset.get('tagset')} ({tag_count} tags)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filter-section",
   "metadata": {},
   "source": [
    "## 3. Filter Coding Scheme for Specific Layers/Tagsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "filter-coding-scheme",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No layers/tagsets matched your filter. layers=[None], tagsets=[None]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m target_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m target_tagset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m filtered_scheme \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_coding_scheme\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoding_scheme\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_layer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtagsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_tagset\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Display the filtered tags\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m filtered_scheme\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m, []):\n",
      "File \u001b[0;32m~/Documents/github/POLIANNA-AI-CC-Project/notebooks/../src/agent/utils.py:116\u001b[0m, in \u001b[0;36mfilter_coding_scheme\u001b[0;34m(coding_scheme, layers, tagsets)\u001b[0m\n\u001b[1;32m    113\u001b[0m         filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(new_layer)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo layers/tagsets matched your filter. layers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, tagsets=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtagsets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered\n",
      "\u001b[0;31mValueError\u001b[0m: No layers/tagsets matched your filter. layers=[None], tagsets=[None]"
     ]
    }
   ],
   "source": [
    "# Filter to focus on Policydesigncharacteristics/Actor\n",
    "#target_layer = \"Policydesigncharacteristics\"\n",
    "#target_tagset = \"Actor\"\n",
    "\n",
    "#target_layer = \"Instrumenttypes\"\n",
    "#target_tagset = \"InstrumentType\"\n",
    "\n",
    "target_layer = None\n",
    "target_tagset = None\n",
    "\n",
    "\n",
    "filtered_scheme = filter_coding_scheme(\n",
    "    coding_scheme, \n",
    "    layers=[target_layer],\n",
    "    tagsets=[target_tagset]\n",
    ")\n",
    "\n",
    "# Display the filtered tags\n",
    "for layer in filtered_scheme.get('layers', []):\n",
    "    for tagset in layer.get('tagsets', []):\n",
    "        print(f\"Tags in {layer.get('layer')}/{tagset.get('tagset')}:\")\n",
    "        for tag in tagset.get('tags', []):\n",
    "            print(f\"  - {tag.get('tag_name')}: {tag.get('tag_description')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-scheme-section",
   "metadata": {},
   "source": [
    "## 4. Create Extended Coding Scheme with Examples\n",
    "\n",
    "The extended coding scheme enhances the original by adding real-world examples for each tag extracted from annotated data. This helps the LLM better understand what to look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "create-extended-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended coding scheme created at /Users/johannesmuller/Documents/github/POLIANNA-AI-CC-Project/data/01_policy_info/Coding_Scheme_Extended.json\n",
      "Added examples to 51 out of 42 tags\n",
      "Minimum occurrences: 1, Maximum examples per tag: 30\n"
     ]
    }
   ],
   "source": [
    "# Create the extended coding scheme\n",
    "extended_scheme_path = create_extended_coding_scheme(\n",
    "    output_name=\"Coding_Scheme_Extended\",\n",
    "    min_occurrences=1,  # Each example must appear at least twice\n",
    "    max_examples=30      # Maximum of 5 examples per tag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load-extended-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended scheme has examples for 42 out of 42 tags\n",
      "Total examples: 1143\n",
      "Average examples per tag with examples: 27.21\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage examples per tag with examples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_examples\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mtags_with_examples\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tags_with_examples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tags have examples yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# View examples for our target layer/tagset\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExamples for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_layer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_tagset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m extended_scheme\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m, []):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m target_layer:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_layer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the extended scheme to examine it\n",
    "extended_scheme = load_coding_scheme(scheme_name=\"Coding_Scheme_Extended\")\n",
    "\n",
    "# Count tags with examples\n",
    "tags_with_examples = 0\n",
    "total_tags = 0\n",
    "total_examples = 0\n",
    "\n",
    "for layer in extended_scheme.get('layers', []):\n",
    "    for tagset in layer.get('tagsets', []):\n",
    "        for tag in tagset.get('tags', []):\n",
    "            total_tags += 1\n",
    "            examples = tag.get('tag_examples', [])\n",
    "            if examples:\n",
    "                tags_with_examples += 1\n",
    "                total_examples += len(examples)\n",
    "\n",
    "print(f\"Extended scheme has examples for {tags_with_examples} out of {total_tags} tags\")\n",
    "print(f\"Total examples: {total_examples}\")\n",
    "print(f\"Average examples per tag with examples: {total_examples / tags_with_examples:.2f}\" if tags_with_examples > 0 else \"No tags have examples yet\")\n",
    "\n",
    "# View examples for our target layer/tagset\n",
    "print(f\"\\nExamples for {target_layer}/{target_tagset}:\")\n",
    "for layer in extended_scheme.get('layers', []):\n",
    "    if layer.get('layer') == target_layer:\n",
    "        for tagset in layer.get('tagsets', []):\n",
    "            if tagset.get('tagset') == target_tagset:\n",
    "                for tag in tagset.get('tags', []):\n",
    "                    examples = tag.get('tag_examples', [])\n",
    "                    print(f\"\\n  - {tag.get('tag_name')}: {len(examples)} examples\")\n",
    "                    for i, example in enumerate(examples):\n",
    "                        print(f\"    {i+1}. \\\"{example}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-article-section",
   "metadata": {},
   "source": [
    "## 5. Load a Sample Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article text (1088 characters):\n",
      "\n",
      "article 10\n",
      "public consultation\n",
      "without prejudice to any other union law requirements, each member state shall ensure that the public is given early and effective opportunities to participate in the preparation of the draft integrated national energy and climate plan — as regards the plans for the 2021 to 2030 period, in the preparation of the final plan well before its adoption — as well as of the long-term strategies referred to in article 15. each member state shall attach to the submission of such documents to the commission a summary of the public's views or provisional views. in so far as directive 2001/42/ec is applicable, consultations undertaken on the draft in accordance with that directive shall be deemed to satisfy the obligations to consult the public under this regulation.\n",
      "each member state shall ensure that the public is informed. each member state shall set reasonable timeframes allowing sufficient time for the public to be informed, to participate and express its views.\n",
      "each member state shall limit administrative complexity when implementing this article.\n"
     ]
    }
   ],
   "source": [
    "# Article ID to work with\n",
    "article_id = \"EU_32018R1999_Title_0_Chapter_2_Section_0_Article_10\"\n",
    "\n",
    "# Load the raw text\n",
    "raw_text = load_raw_text(article_id)\n",
    "print(f\"Article text ({len(raw_text)} characters):\\n\")\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-annotations-section",
   "metadata": {},
   "source": [
    "## 6. Load Curated Annotations for the Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-annotations",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m filtered_annotations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m curated_annotations:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ann\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[43mtarget_layer\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m ann\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m target_tagset:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Create a clean version without metadata fields\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         clean_ann \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ann\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     10\u001b[0m         filtered_annotations\u001b[38;5;241m.\u001b[39mappend(clean_ann)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_layer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the curated annotations\n",
    "curated_annotations = load_curated_annotations(article_id)\n",
    "\n",
    "# Filter to our target layer/tagset\n",
    "filtered_annotations = []\n",
    "for ann in curated_annotations:\n",
    "    if ann.get('layer') == target_layer and ann.get('feature') == target_tagset:\n",
    "        # Create a clean version without metadata fields\n",
    "        clean_ann = {k: v for k, v in ann.items() if k not in ['span_id', 'tokens']}\n",
    "        filtered_annotations.append(clean_ann)\n",
    "\n",
    "print(f\"Found {len(filtered_annotations)} annotations in {target_layer}/{target_tagset}:\")\n",
    "for ann in filtered_annotations:\n",
    "    print(f\"- {ann['tag']}: '{ann['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "few-shot-section",
   "metadata": {},
   "source": [
    "## 7. Generate Few-Shot Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "few-shot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load few-shot examples\n",
    "few_shot_examples = load_few_shot_examples(\n",
    "    num_examples=2,\n",
    "    layers=[target_layer],\n",
    "    tagsets=[target_tagset],\n",
    "    exclude_article_ids=[article_id]\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(few_shot_examples)} few-shot examples\")\n",
    "\n",
    "# Display the first example\n",
    "if few_shot_examples:\n",
    "    example = few_shot_examples[0]\n",
    "    print(f\"\\nExample Text:\\n{example['text'][:200]}...\")\n",
    "    print(f\"\\nExample Annotations ({len(example['annotations'])}):\\n\")\n",
    "    for ann in example['annotations']:\n",
    "        print(f\"- {ann['tag']}: '{ann['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-section",
   "metadata": {},
   "source": [
    "## 8. Create LLM Prompt with Extended Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the annotation prompt with extended coding scheme\n",
    "prompt = prepare_annotation_prompt(\n",
    "    raw_text=raw_text,\n",
    "    coding_scheme=extended_scheme,  # Use the extended scheme with examples\n",
    "    layers=[target_layer],\n",
    "    tagsets=[target_tagset],\n",
    "    few_shot_examples=few_shot_examples,\n",
    "    use_extended_scheme=True  # Enable special formatting for examples\n",
    ")\n",
    "\n",
    "# Display a shortened version of the prompt\n",
    "print(f\"Prompt length: {len(prompt)} characters\")\n",
    "print(\"Prompt preview (first 1000 characters):\")\n",
    "print(prompt[:1000] + \"...\\n[truncated]...\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annotate-section",
   "metadata": {},
   "source": [
    "## 9. Annotate the Article with Standard Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annotate-article-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate the article with the standard coding scheme\n",
    "standard_annotations = annotate_article(\n",
    "    article_id=article_id,\n",
    "    layers=[target_layer],\n",
    "    tagsets=[target_tagset],\n",
    "    num_examples=2,\n",
    "    save_result=True,\n",
    "    use_extended_scheme=False,  # Use standard scheme\n",
    "    scheme_name=\"Coding_Scheme\"  # Explicitly use the standard scheme\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(standard_annotations)} annotations with standard scheme\")\n",
    "for ann in standard_annotations:\n",
    "    print(f\"- {ann['layer']}/{ann['feature']}/{ann['tag']}: '{ann['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annotate-section-extended",
   "metadata": {},
   "source": [
    "## 10. Annotate the Article with Extended Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annotate-article-extended",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate the article with the extended coding scheme\n",
    "extended_annotations = annotate_article(\n",
    "    article_id=article_id,\n",
    "    layers=[target_layer],\n",
    "    tagsets=[target_tagset],\n",
    "    num_examples=2,\n",
    "    save_result=True,\n",
    "    use_extended_scheme=True,  # Use extended scheme with examples\n",
    "    scheme_name=\"Coding_Scheme_Extended\"  # Explicitly use the extended scheme\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(extended_annotations)} annotations with extended scheme\")\n",
    "for ann in extended_annotations:\n",
    "    print(f\"- {ann['layer']}/{ann['feature']}/{ann['tag']}: '{ann['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-section",
   "metadata": {},
   "source": [
    "## 11. Compare Against Curated Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-annotations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display curated, standard, and extended annotations side by side\n",
    "print(\"Curated vs. Generated Annotations:\\n\")\n",
    "\n",
    "print(\"Curated Annotations:\")\n",
    "for ann in filtered_annotations:\n",
    "    print(f\"- {ann['tag']}: '{ann['text']}' ({ann['start']}:{ann['stop']})\")\n",
    "\n",
    "print(\"\\nStandard Scheme Annotations:\")\n",
    "for ann in standard_annotations:\n",
    "    print(f\"- {ann['tag']}: '{ann['text']}' ({ann['start']}:{ann['stop']})\")\n",
    "    \n",
    "print(\"\\nExtended Scheme Annotations:\")\n",
    "for ann in extended_annotations:\n",
    "    print(f\"- {ann['tag']}: '{ann['text']}' ({ann['start']}:{ann['stop']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b4fbf",
   "metadata": {},
   "source": [
    "## 12. Safe results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a8684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both annotation sets to different files for comparison\n",
    "root_dir = get_project_root()\n",
    "article_dir = os.path.join(root_dir, 'data', '03b_processed_to_json', article_id)\n",
    "\n",
    "# Save standard annotations to a separate file\n",
    "standard_path = os.path.join(article_dir, 'Generated_Annotations_Standard.json')\n",
    "with open(standard_path, 'w') as f:\n",
    "    json.dump(standard_annotations, f, indent=2)\n",
    "\n",
    "# Save extended annotations to a separate file\n",
    "extended_path = os.path.join(article_dir, 'Generated_Annotations_Extended.json')\n",
    "with open(extended_path, 'w') as f:\n",
    "    json.dump(extended_annotations, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7030ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POLIANNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
