{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdda930",
   "metadata": {},
   "source": [
    "# LLM-Based Automatic Policy Text Classifier\n",
    "This notebook demonstrates a multi-step approach to automatically annotate policy articles using an LLM (Anthropic Claude), informed by the coding scheme in the Appendix and Codebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cabb6c6",
   "metadata": {},
   "source": [
    "## 1. Load Required Libraries and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d742e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:31:20.143978Z",
     "start_time": "2025-05-10T10:31:20.101148Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Dict\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "LLM_MODEL = os.getenv('LLM_MODEL', 'claude-3-opus-20240229')\n",
    "LLM_TEMPERATURE = float(os.getenv('LLM_TEMPERATURE', '0.2'))\n",
    "assert ANTHROPIC_API_KEY, 'Please set your ANTHROPIC_API_KEY in the .env file.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b104a40",
   "metadata": {},
   "source": [
    "# 2. Test LLM connection with a short query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7a9267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM connection...\n",
      "LLM test response: Here is the JSON array with a single object as requested:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"layer\": \"Test\",\n",
      "    \"feature\": \"TestFeature\",\n",
      "    \"tag\": \"TestTag\",\n",
      "    \"text\": \"test span\"\n",
      "  }\n",
      "]\n",
      "LLM test response: Here is the JSON array with a single object as requested:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"layer\": \"Test\",\n",
      "    \"feature\": \"TestFeature\",\n",
      "    \"tag\": \"TestTag\",\n",
      "    \"text\": \"test span\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('Testing LLM connection...')\n",
    "test_prompt = \"Hello! Please return a JSON array with a single object: {\\\"layer\\\": \\\"Test\\\", \\\"feature\\\": \\\"TestFeature\\\", \\\"tag\\\": \\\"TestTag\\\", \\\"text\\\": \\\"test span\\\"}\"\n",
    "headers = {\n",
    "    'x-api-key': ANTHROPIC_API_KEY,\n",
    "    'anthropic-version': '2023-06-01',\n",
    "    'content-type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    'model': LLM_MODEL,\n",
    "    'max_tokens': 128,\n",
    "    'temperature': LLM_TEMPERATURE,\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': test_prompt\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "try:\n",
    "    response = requests.post('https://api.anthropic.com/v1/messages', headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    content = response.json()['content'][0]['text']\n",
    "    print('LLM test response:', content)\n",
    "except Exception as e:\n",
    "    print('LLM connection test failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb20d99",
   "metadata": {},
   "source": [
    "## 3. Load Coding Scheme (from Codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4dccab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded coding scheme keys: ['layers']\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, load coding scheme from JSON (should be extracted from PDF in production)\n",
    "with open('data/01_policy_info/Coding_Scheme.json', 'r') as f:\n",
    "    coding_scheme = json.load(f)\n",
    "print('Loaded coding scheme keys:', list(coding_scheme.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6202f",
   "metadata": {},
   "source": [
    "## 4. Define Anthropic Claude LLM Annotation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_coding_scheme(coding_scheme, layers=None, tagsets=None):\n",
    "    # Filter coding scheme dict to only include selected layers/tagsets\n",
    "    if not layers and not tagsets:\n",
    "        return coding_scheme\n",
    "    if \"layers\" not in coding_scheme:\n",
    "        raise ValueError(\"Coding scheme JSON does not contain a 'layers' key\")\n",
    "    filtered = {\"layers\": []}\n",
    "    for layer in coding_scheme.get(\"layers\", []):\n",
    "        if \"layer\" not in layer:\n",
    "            raise KeyError(f\"Layer object missing 'layer' field: {layer}\")\n",
    "        if layers and layer[\"layer\"] not in layers:\n",
    "            continue\n",
    "        new_layer = {k: v for k, v in layer.items() if k != \"tagsets\"}\n",
    "        new_layer[\"tagsets\"] = []\n",
    "        for tagset in layer.get(\"tagsets\", []):\n",
    "            if \"tagset\" not in tagset:\n",
    "                raise KeyError(f\"Tagset object missing 'tagset' field: {tagset}\")\n",
    "            if tagsets and tagset[\"tagset\"] not in tagsets:\n",
    "                continue\n",
    "            new_layer[\"tagsets\"].append(tagset)\n",
    "        if new_layer[\"tagsets\"] or not tagsets:\n",
    "            filtered[\"layers\"].append(new_layer)\n",
    "    if not filtered[\"layers\"]:\n",
    "        raise ValueError(f\"No layers/tagsets matched your filter. layers={layers}, tagsets={tagsets}\")\n",
    "    return filtered\n",
    "\n",
    "def load_few_shot_examples(base_dir, layers=None, tagsets=None, max_lines=6, n=3):\n",
    "    folders = glob.glob(os.path.join(base_dir, \"*/\"))\n",
    "    random.shuffle(folders)\n",
    "    examples = []\n",
    "    skipped_count = 0\n",
    "    \n",
    "    # Build tag_name lookup for validation\n",
    "    valid_tags = {}\n",
    "    for l in coding_scheme[\"layers\"]:\n",
    "        if not layers or l[\"layer\"] in layers:\n",
    "            layer_tags = {}\n",
    "            for ts in l.get(\"tagsets\", []):\n",
    "                if not tagsets or ts[\"tagset\"] in tagsets:\n",
    "                    layer_tags[ts[\"tagset\"]] = [t[\"tag_name\"] for t in ts.get(\"tags\", [])]\n",
    "            if layer_tags:\n",
    "                valid_tags[l[\"layer\"]] = layer_tags\n",
    "    \n",
    "    for folder in folders:\n",
    "        try:\n",
    "            with open(os.path.join(folder, \"Raw_Text.txt\")) as f:\n",
    "                raw = f.read().strip()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POLIANNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
